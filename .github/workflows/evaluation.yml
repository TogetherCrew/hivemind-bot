name: RAG Evaluation

on:
  workflow_dispatch: {}

jobs:
  evaluate:
    permissions:
      id-token: write
      contents: read
    runs-on: ubuntu-latest

    services:
      qdrant:
        image: qdrant/qdrant:v1.9.2
        ports:
          - 6333:6333

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt --no-cache-dir
          python -m spacy download en_core_web_sm

      - name: Install AWS CLI
        uses: aws-actions/setup-aws-cli@v4

      - name: Validate AWS role ARN secret
        run: |
          if [ -z "${{ secrets.AWS_EVAL_ROLE_ARN }}" ]; then
            echo "AWS_EVAL_ROLE_ARN secret is not set. Please add it in the repository or org secrets." >&2
            exit 1
          fi

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_EVAL_ROLE_ARN }}
          aws-region: us-east-1
          audience: sts.amazonaws.com

      - name: Verify AWS identity
        run: |
          aws sts get-caller-identity || { echo "Failed to assume role. Check role trust policy and inputs." >&2; exit 1; }

      - name: Fetch evaluation dataset from S3
        env:
          DATASET_S3_URI: ${{ vars.EVAL_DATASET_S3_URI }}
        run: |
          if [ -z "$DATASET_S3_URI" ]; then
            echo "EVAL_DATASET_S3_URI repo variable is not set (e.g., s3://bucket/eval-datasets/testset_hybrid_extended_ooc_data.csv)" >&2
            exit 1
          fi
          mkdir -p evaluation/datasets
          aws s3 cp "$DATASET_S3_URI" "evaluation/datasets/testset_hybrid_extended_ooc_data.csv"

      - name: Wait for Qdrant to be ready
        run: |
          timeout 120 bash -c 'until curl -sf http://localhost:6333/collections >/dev/null; do echo "Waiting for Qdrant..."; sleep 3; done'

      - name: Restore Qdrant collections from S3 snapshots
        env:
          SUMMARY_SNAPSHOT_ARN: ${{ vars.EVAL_QDRANT_SUMMARY_SNAPSHOT_ARN }}
          BASE_SNAPSHOT_ARN: ${{ vars.EVAL_QDRANT_BASE_SNAPSHOT_ARN }}
        run: |
          set -eo pipefail
          to_s3_uri() { echo "$1" | sed -E 's#^arn:aws:s3:::(.*)#s3://\1#'; }

          DEFAULT_SUMMARY_ARN="arn:aws:s3:::togethercrew-staging/eval-datasets/6579c364f1120850414e0dc5_65b18d9b5f88faae22760e97_summary-5685328549633988-2025-08-21-11-54-10.snapshot"
          DEFAULT_BASE_ARN="arn:aws:s3:::togethercrew-staging/eval-datasets/6579c364f1120850414e0dc5_65b18d9b5f88faae22760e97-5685328549633988-2025-08-21-11-53-57.snapshot"

          SUMMARY_ARN="${SUMMARY_SNAPSHOT_ARN:-$DEFAULT_SUMMARY_ARN}"
          BASE_ARN="${BASE_SNAPSHOT_ARN:-$DEFAULT_BASE_ARN}"

          mkdir -p snapshots
          echo "Downloading snapshots from S3..."
          aws s3 cp "$(to_s3_uri "$SUMMARY_ARN")" snapshots/summary.snapshot
          aws s3 cp "$(to_s3_uri "$BASE_ARN")" snapshots/base.snapshot

          echo "Restoring Qdrant collections via upload..."
          curl -sf -X POST "http://localhost:6333/collections/1234_4321_summary/snapshots/upload" \
            -F "snapshot=@snapshots/summary.snapshot"

          curl -sf -X POST "http://localhost:6333/collections/1234_4321/snapshots/upload" \
            -F "snapshot=@snapshots/base.snapshot"

          echo "Validating restored collections..."
          curl -sf "http://localhost:6333/collections/1234_4321_summary" >/dev/null
          curl -sf "http://localhost:6333/collections/1234_4321" >/dev/null

      - name: Run evaluation
        env:
          QDRANT_HOST: localhost
          QDRANT_PORT: '6333'
          QDRANT_API_KEY: ''
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          EVAL_DATA_ROOT: evaluation
        run: |
          python evaluation/evaluation.py \
            --community-id 1234 \
            --platform-id 4321

      - name: Compute averages and summarize
        id: summarize
        run: |
          python - << 'PY'
          import os
          import pandas as pd
          import json
          from pathlib import Path

          results_csv = Path('results.csv')
          cost_json = Path('results_cost.json')

          assert results_csv.exists(), 'results.csv not found'
          df = pd.read_csv(results_csv)

          metrics = ['faithfulness','answer_relevancy','context_precision','context_recall']
          avgs = {m: float(df[m].mean()) for m in metrics if m in df.columns}

          cost_payload = {}
          if cost_json.exists():
            cost_payload = json.loads(cost_json.read_text())

          print('::group::Evaluation Averages')
          for k,v in avgs.items():
            print(f"{k}: {v:.4f}")
          print('::endgroup::')

          # Write GitHub Job Summary
          summary_lines = [
            '# Evaluation Summary',
            '',
            '| Metric | Average |',
            '|---|---:|',
          ]
          for k,v in avgs.items():
            summary_lines.append(f"| {k} | {v:.4f} |")

          if cost_payload:
            summary_lines += [
              '',
              '## Cost',
              f"- model: {cost_payload.get('model')}",
              f"- input_rate: {cost_payload.get('input_rate')}",
              f"- output_rate: {cost_payload.get('output_rate')}",
              f"- total_tokens: {cost_payload.get('total_tokens')}",
              f"- total_cost: {cost_payload.get('total_cost')}",
            ]

          Path(os.environ['GITHUB_STEP_SUMMARY']).write_text('\n'.join(summary_lines))
          PY

      - name: Upload results.csv
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: results-csv
          path: results.csv

      - name: Upload results_cost.json
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: results-cost
          path: results_cost.json


